{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using symmetry in the problems to make quantum computing more efficient\n",
    "We can use quantum computers to help us with machine learning. By utilizing variational quantum circuits, we can use quantum computers to learn patterns in data.\n",
    "\n",
    "In order for this to work well, we need to come up with a way to encode the patterns we want to learn into the quantum computer. Especially on near-term quantum hardware, this requires quite some resources. One way to reduce these resource requirements and learn more efficiently is to take advantage of symmetries in the data we are trying to learn.\n",
    "\n",
    "One approach is taken in [this paper](https://journals.aps.org/prxquantum/abstract/10.1103/PRXQuantum.4.010328) (CC-BY 4.0, Johannes Jakob Meyer, Marian Mularski, Elies Gil-Fuster, Antonio Anna Mele, Francesco Arzani, Alissa Wilms, and Jens Eisert) and we will use it as a guideline for this challenge. A huge thank you to the authors for providing this idea and explaing it so well :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Circuit without symmetries\n",
    "\n",
    "In this notebook we implement the same Tic-Tac-Toe model but without taking into account the symmetries of the problem. This means that we have a different parameter for each single and two-qubit gate. Our aim is to compare the performance of both approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the circuit\n",
    "\n",
    "Now it is time to build the circuit. For this, we will start with some basic imports. For todays challenge, we use qiskit. However, this can be also acchieved with PennyLane or Cirq.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the data\n",
    "\n",
    "The basic element needed for your first program is the QuantumCircuit. We begin by creating a `QuantumCircuit` comprised of nine qubits.\n",
    "\n",
    "The equivariant embedding is constructed by encoding the different numerical values that represent a game via a Pauli-X rotation on separate qubits that we view in a planar grid. To distribute the three data features equidistantly, we use a multiple of 2Ï€/3 for the rotation angle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-31T05:04:39.584692Z",
     "start_time": "2021-07-31T05:04:39.573755Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boards:  [['x', 'x', 'x', 'x', 'o', 'o', '', 'o', ''], ['o', 'x', '', 'x', '', '', 'o', 'o', 'x'], ['o', '', 'o', 'x', 'x', 'o', 'x', '', ''], ['o', 'x', 'x', '', 'o', 'x', '', '', 'o']]\n",
      "winners:  [[0, 0, 1], [1, 0, 0], [0, 1, 0], [1, 0, 0]]\n",
      "1413\n",
      "1413\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from qiskit import *\n",
    "from utils import *\n",
    "\n",
    "boards, winners = load_boards(include_draws = True)\n",
    "\n",
    "print(\"boards: \", boards[1:5])\n",
    "print(\"winners: \",  winners[1:5])\n",
    "print(len(boards))\n",
    "print(len(winners))\n",
    "\n",
    "# Create a Quantum Circuit acting on a quantum register of nine qubits\n",
    "def make_circuit(x, params, layers):\n",
    "    circ = QuantumCircuit(9)\n",
    "    for i in range(layers):\n",
    "        l = i*34\n",
    "        encode_data(x, circ)\n",
    "        # use functions for no symmetry\n",
    "        ns_add_single_qubit_gates(params[l:l+18], circ)\n",
    "        ns_add_two_qubit_gates(params[l+18:l+34], circ)\n",
    "\n",
    "    return circ\n",
    "\n",
    "layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "Now that we have our circuit, however, the results obtained are not quite what we wanted. So, we still need to train it on the given data. \n",
    "\n",
    "Therefore, we need to define, how far we are away from the expected result. One way to do this, is to use the l2_loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "def l2_loss(output, target):\n",
    "    output, target = np.array(output), np.array(target)\n",
    "    return np.sum(np.abs(output - target)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example train data:  ['x' 'x' '' 'o' 'x' 'o' '' 'o' 'x'] [0 0 1]\n"
     ]
    }
   ],
   "source": [
    "x = boards\n",
    "y = winners\n",
    "\n",
    "# shuffle the indices\n",
    "shuffle_indices = np.random.permutation(len(x))\n",
    "train_size = int(len(x) * 0.3)\n",
    "\n",
    "# split the indices into training and testing sets\n",
    "train_indices = np.array(shuffle_indices[:train_size])\n",
    "test_indices = np.array(shuffle_indices[train_size:])\n",
    "\n",
    "# create the training and testing sets\n",
    "x_train, y_train = np.take(x, train_indices, axis=0), np.take(y, train_indices, axis=0)\n",
    "x_test, y_test = np.take(x, test_indices, axis=0), np.take(y, test_indices, axis=0)\n",
    "\n",
    "\n",
    "print(\"Example train data: \", x_train[17], y_train[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial parameters: [5.86327071 0.11985395 3.10866994 1.35522317 5.37179068 0.168139\n",
      " 5.47940569 2.65101153 0.8496218  5.48818343 2.3003046  1.87901355\n",
      " 5.55088962 2.85507062 2.110803   1.53965332 3.91217179 2.40975143\n",
      " 4.98609325 0.53301517 4.57266451 2.58594659 0.24111943 3.99379298\n",
      " 0.80089924 0.46371111 4.49781824 4.62207459 1.96949282 5.91430477\n",
      " 6.15184067 3.62651275 3.0990945  0.87506631]\n",
      "597.0258021063675\n",
      "479.930642804722\n",
      "495.2985662933062\n",
      "578.3333103612254\n",
      "538.6319102922549\n",
      "529.1390482406719\n",
      "494.36419929575425\n",
      "577.3252444659319\n",
      "575.9158141089938\n",
      "491.2860497537219\n",
      "479.57576803206734\n",
      "596.7424598745738\n",
      "521.5693863100095\n",
      "543.2627212037536\n",
      "577.1843450220243\n",
      "491.81357516756884\n",
      "536.8394275893872\n",
      "529.7481348606384\n",
      "543.5889229336243\n",
      "521.3966477676358\n",
      "598.4069843655661\n",
      "487.44774773887394\n",
      "578.6442472922968\n",
      "495.69152178366767\n",
      "544.0447069420213\n",
      "522.8681398151637\n",
      "576.9803040207471\n",
      "492.0481917760122\n",
      "545.1408555374106\n",
      "520.2258439452953\n",
      "537.0423224599848\n",
      "529.5104689307484\n",
      "536.9141640434348\n",
      "529.6917374007376\n",
      "487.28867653154515\n",
      "598.52073739158\n",
      "578.6697052520993\n",
      "495.3874943160314\n",
      "598.5570607940855\n",
      "487.3328158806452\n",
      "596.6806690213441\n",
      "479.9292243441802\n",
      "529.6841755592086\n",
      "536.8407811365902\n",
      "543.5017291610283\n",
      "521.4719468456695\n",
      "529.357747841814\n",
      "538.67967867286\n",
      "578.3816266701551\n",
      "495.2584487901627\n",
      "529.4328743874039\n",
      "537.3642735190327\n",
      "540.0452421711805\n",
      "524.3633850015501\n",
      "580.1428033512315\n",
      "480.71508719157765\n",
      "429.93900539160387\n",
      "424.1506404736156\n",
      "439.4592802275839\n",
      "434.18179192090776\n",
      "431.2192801661209\n",
      "422.74504254932765\n",
      "422.9568980634999\n",
      "429.0592947132815\n",
      "424.58992127915076\n",
      "434.41209822631026\n",
      "431.4376458680062\n",
      "431.0484315917922\n",
      "424.63631456395734\n",
      "424.88997703247435\n",
      "424.49909180909253\n",
      "425.1711227576807\n",
      "422.9437059160642\n",
      "424.54287571458246\n",
      "424.7244284921568\n",
      "422.9002313668159\n",
      "424.5706308080022\n",
      "424.46782313735025\n",
      "427.8526015055362\n",
      "426.213845513609\n",
      "425.7658689733435\n",
      "423.2810153238845\n",
      "427.08183909896144\n",
      "425.2608515273771\n",
      "426.83193495640205\n",
      "425.4814809299183\n",
      "425.66903781749056\n",
      "424.96663197629266\n",
      "423.8527073768319\n",
      "424.29372672988876\n",
      "424.8309257212372\n",
      "424.01561613500394\n",
      "423.3607834705017\n",
      "422.5627103883449\n",
      "423.28829048130297\n",
      "424.95674344523917\n",
      "424.7338816364251\n",
      "424.0075321374674\n",
      "423.81789279694357\n",
      "424.17763628403765\n",
      "424.11653496502186\n",
      "423.01385986780207\n",
      "427.31305377509824\n",
      "425.730125452281\n",
      "423.0963638386208\n",
      "422.6367805192488\n",
      "425.2232664178799\n",
      "424.5074106299463\n",
      "429.4734041250969\n",
      "430.22920485990164\n",
      "422.5160377268978\n",
      "423.6401491298575\n",
      "427.07545662279307\n",
      "425.56542790536935\n",
      "429.7300192491717\n",
      "428.0994115321055\n",
      "424.0033101474588\n",
      "422.8249103418381\n",
      "429.66247905088215\n",
      "429.44389008875106\n",
      "428.1964712718943\n",
      "429.17434744686443\n",
      "424.39139989041917\n",
      "423.78106407490526\n",
      "428.20931550765107\n",
      "429.0599827628836\n",
      "424.5082841728041\n",
      "423.0772570599348\n",
      "424.1401605879947\n",
      "423.3961482979636\n",
      "423.03608998261296\n",
      "423.1156746853678\n",
      "424.08467375583234\n",
      "425.0217527425534\n",
      "423.41892059622404\n",
      "422.40197948986287\n",
      "428.64980806214425\n",
      "428.2776718388135\n",
      "425.9512006787261\n",
      "424.70000995066476\n",
      "424.9712398997375\n",
      "427.013540497527\n",
      "422.53258194763475\n",
      "424.00542994231904\n",
      "425.86189888418653\n",
      "426.8811530869074\n",
      "428.93462137625664\n",
      "428.8996432566229\n",
      "429.04150981059155\n",
      "428.8340347483978\n",
      "425.01770718669206\n",
      "425.4368426808306\n",
      "423.2184581111777\n",
      "423.8423142399313\n",
      "423.865569321413\n",
      "422.6090992304427\n",
      "423.1085988040754\n",
      "423.9280722395185\n",
      "424.0452417755008\n",
      "424.7878449311995\n",
      "422.8469492114731\n",
      "422.28908552647454\n",
      "422.26238320776196\n",
      "422.87031895285816\n",
      "423.1082288968147\n",
      "423.71413197894066\n",
      "424.379084545378\n",
      "422.9988882501223\n",
      "424.1263773661513\n",
      "424.49081334388643\n",
      "424.152586070824\n",
      "423.1201409570402\n",
      "422.7190424685814\n",
      "424.63122065747285\n",
      "423.51405831637476\n",
      "423.30988034342306\n",
      "422.05422718273496\n",
      "423.24824504319724\n",
      "425.37154646202333\n",
      "425.6232843456896\n",
      "423.7324886047622\n",
      "422.43806102971087\n",
      "426.21947009409274\n",
      "424.85827422844676\n",
      "422.95728576594433\n",
      "421.9252474433413\n",
      "422.7782996373412\n",
      "424.46709668771473\n",
      "428.25619875981937\n",
      "427.1320049605935\n",
      "425.5067295431402\n",
      "426.3668673213246\n",
      "428.24456104398587\n",
      "428.40440464863235\n",
      "422.6373446343165\n",
      "422.17448559684965\n",
      "425.39225266700583\n",
      "424.41783316087987\n",
      "422.59219992295004\n",
      "422.17550664679976\n",
      "423.4207396306893\n",
      "424.8046126472015\n",
      "426.7992433028058\n",
      "428.33963444947733\n",
      "422.9523508324347\n",
      "424.03655686548836\n",
      "422.51985597562043\n",
      "422.74162931286673\n",
      "422.215884630118\n",
      "423.7422015137453\n",
      "427.99153990058284\n",
      "428.247397643222\n",
      "425.45887138892044\n",
      "426.0732434299577\n",
      "422.6337642988417\n",
      "422.6034613007065\n",
      "428.0093752260263\n",
      "426.9265371410236\n",
      "423.4419474386633\n",
      "422.346650718574\n",
      "428.10794817439006\n",
      "427.9365035146655\n",
      "422.89016576307114\n",
      "423.39275214580925\n",
      "424.4029895978055\n",
      "426.1540753536045\n",
      "423.49600555248867\n",
      "422.7063801054486\n",
      "425.05264243567456\n",
      "424.2284758076995\n",
      "422.6292467701152\n",
      "422.5434306758053\n",
      "423.74692681778356\n",
      "424.16013006110404\n",
      "424.4787362025967\n",
      "423.44007409993134\n",
      "423.3893977553336\n",
      "422.3332769480042\n",
      "424.4281771558887\n",
      "426.03344901981944\n",
      "424.85143874831914\n",
      "424.3237770162108\n",
      "424.1618411555543\n",
      "423.5951130776681\n",
      "425.2952518642258\n",
      "425.84500701559404\n",
      "422.6403897051474\n",
      "422.34350151740716\n",
      "423.4584622153734\n",
      "424.3412488212454\n",
      "421.3477516040099\n",
      "Finished optimizing.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import Estimator\n",
    "\n",
    "# Define the optimizer\n",
    "from qiskit.algorithms.optimizers import SPSA\n",
    "optimizer = SPSA(maxiter = 100)\n",
    "\n",
    "\n",
    "\n",
    "# Define the cost function to be minimized by the optimizer\n",
    "def cost_function(params):\n",
    "\n",
    "    cost = 0\n",
    "    # TODO: Calculate the cost and return them\n",
    "    estimator = Estimator()\n",
    "    observables = (\n",
    "            SparsePauliOp(\"ZIZIZIZII\") / 4.0,\n",
    "            SparsePauliOp(\"IZIZIZIZI\") / 4.0,\n",
    "            SparsePauliOp(\"IIIIIIIIZ\")\n",
    "        )\n",
    "    \n",
    "    for x, y in zip(x_train, y_train):\n",
    "\n",
    "        circ = make_circuit(x, params, layers)\n",
    "        circuits = (\n",
    "            circ,\n",
    "            circ,\n",
    "            circ\n",
    "        )\n",
    "\n",
    "        job = estimator.run(circuits, observables)\n",
    "        result = job.result().values.tolist()\n",
    "        \n",
    "        cost += l2_loss(result, y)\n",
    "        \n",
    "    print(cost)\n",
    "    return cost\n",
    "\n",
    "# Initialize the parameters\n",
    "params = np.random.rand(34*layers)*2*np.pi\n",
    "\n",
    "# Train the circuit\n",
    "print('Initial parameters:', params)\n",
    "\n",
    "# Check the qiskit docs to figure out how to start an optimizer\n",
    "result = optimizer.minimize(cost_function, x0 = params)\n",
    "print(\"Finished optimizing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model\n",
    "The final model can then be used to predict the winner for any given tic-tac-toe board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data, params):\n",
    "    \n",
    "    circ = make_circuit(data, params, layers)\n",
    "\n",
    "    #TODO:  create observables and measure\n",
    "    exp_val_o = 0\n",
    "    exp_val_draw = 0\n",
    "    exp_val_x = 0\n",
    "    \n",
    "    estimator = Estimator()\n",
    "    observables = (\n",
    "            SparsePauliOp(\"ZIZIZIZII\") / 4.0,\n",
    "            SparsePauliOp(\"IZIZIZIZI\") / 4.0,\n",
    "            SparsePauliOp(\"IIIIIIIIZ\")\n",
    "        )\n",
    "    \n",
    "    circuits = (\n",
    "            circ,\n",
    "            circ,\n",
    "            circ\n",
    "        )\n",
    "\n",
    "    job = estimator.run(circuits, observables)\n",
    "    result = job.result().values.tolist()\n",
    "    exp_val_o = result[0]\n",
    "    exp_val_draw = result[1]\n",
    "    exp_val_x = result[2]\n",
    "    \n",
    "    \n",
    "\n",
    "    return [exp_val_o, exp_val_draw, exp_val_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:\n",
      "Correct guesses: 95/423 (22%)\n",
      "L2 Loss: 0.9960939754231912\n",
      "Test data:\n",
      "Correct guesses: 238/990 (24%)\n",
      "L2 Loss: 0.9950416678354778\n"
     ]
    }
   ],
   "source": [
    "def test_model(params, x_data, y_data):\n",
    "    total_loss = 0\n",
    "    correct_guesses = 0\n",
    "    i = 0\n",
    "    for x, y in zip(x_data, y_data):\n",
    "        pred = predict(x, params)\n",
    "        pred_discrete = [0, 0, 0]\n",
    "        pred_discrete[np.argmax(np.abs(pred))] = 1\n",
    "        total_loss += l2_loss(pred, y)\n",
    "        correct_guesses += np.all(pred_discrete == y)\n",
    "        \n",
    "        if i % 100 == 0 and False: \n",
    "            print(\"Correct output:\", y)\n",
    "            print(\"Actual output:\", pred)\n",
    "            print(\"Discrete_output:\", pred_discrete)\n",
    "            print(\"---------------\")\n",
    "        i+= 1\n",
    "\n",
    "    total_loss = total_loss / len(x_data)\n",
    "\n",
    "    print(\"Correct guesses: {}/{} ({}%)\".format(correct_guesses, len(x_data), round(correct_guesses/len(x_data)*100)))\n",
    "    print(\"L2 Loss: {}\".format(total_loss))\n",
    "\n",
    "print(\"Train data:\")\n",
    "test_model(result.x, x_train, y_train)\n",
    "\n",
    "print(\"Test data:\")\n",
    "test_model(result.x, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
